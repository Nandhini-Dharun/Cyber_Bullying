{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6fV7lgMrZxDT",
        "outputId": "0f19cb65-7c63-4f31-94fc-ad93012ebd79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (from imblearn) (0.13.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading gradio-5.20.0-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio, imblearn\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.0 gradio-client-1.7.2 groovy-0.1.2 imblearn-0.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.0 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn numpy pandas nltk matplotlib imblearn gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e52ZWXgBaSQ6",
        "outputId": "ece4fb0c-b4db-4138-dbb1-ab8fc41f5ab9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ✅ Define emoji-based classification\n",
        "CYBERBULLYING_EMOJIS = {\"😡\", \"👊\", \"💀\", \"🤬\", \"😠\", \"👿\", \"🖕\", \"💢\", \"🔪\"}\n",
        "NON_CYBERBULLYING_EMOJIS = {\"😊\", \"❤️\", \"👍\", \"😁\", \"😇\", \"🎉\", \"😂\", \"💖\", \"🥰\"}\n",
        "\n",
        "# ✅ Function to check if input contains **only emojis**\n",
        "def contains_only_emojis(text):\n",
        "    text = text.strip()\n",
        "    return all(char in emoji.EMOJI_DATA for char in text) and len(text) > 0\n",
        "\n",
        "# ✅ Fully Fixed Emoji Classification Function\n",
        "def classify_emoji(input_text):\n",
        "    input_text = input_text.strip()\n",
        "    if contains_only_emojis(input_text):  # If the input is only emojis\n",
        "        # Check each emoji and classify\n",
        "        for char in input_text:\n",
        "            if char in CYBERBULLYING_EMOJIS:\n",
        "                return \"Cyberbullying\"\n",
        "            elif char in NON_CYBERBULLYING_EMOJIS:\n",
        "                return \"Non-Cyberbullying\"\n",
        "        return \"Non-Cyberbullying\"  # Default if no match is found\n",
        "    return None  # If it's mixed with text, process normally\n",
        "\n",
        "# ✅ Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "# ✅ Load dataset (Update path if needed)\n",
        "dataset_path = \"expanded_cyberbullying_dataset.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# ✅ Preprocess dataset\n",
        "df[\"processed_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "# ✅ Split dataset into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"processed_text\"], df[\"label\"], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Create a Naïve Bayes classifier pipeline\n",
        "model_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),  # Convert text to numerical features\n",
        "    (\"classifier\", MultinomialNB())  # Train Naïve Bayes model\n",
        "])\n",
        "\n",
        "# ✅ Train the model\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Evaluate model performance\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred, target_names=[\"Non-Cyberbullying\", \"Cyberbullying\"])\n",
        "\n",
        "# ✅ Print results\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n",
        "\n",
        "# ✅ Final cyberbullying detection function (Text + Emoji)\n",
        "def predict_cyberbullying(user_input):\n",
        "    emoji_prediction = classify_emoji(user_input)  # Check for emoji classification first\n",
        "    if emoji_prediction:\n",
        "        return emoji_prediction  # If emoji-based classification is valid, return it\n",
        "\n",
        "    # Otherwise, classify using the trained model\n",
        "    processed_input = preprocess_text(user_input)\n",
        "    prediction = model_pipeline.predict([processed_input])[0]\n",
        "    return \"Cyberbullying\" if prediction == 1 else \"Non-Cyberbullying\"\n",
        "\n",
        "# ✅ Testing the system again\n",
        "test_inputs = [\"I hate you!\", \"You are amazing! 😊\",\"🫶🏽\", \"😡\", \"You are a failure!\", \"Keep up the great work! 👍\"]\n",
        "for text in test_inputs:\n",
        "    print(f\"Input: {text} --> Prediction: {predict_cyberbullying(text)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGf-jfVNZzpD",
        "outputId": "03631a7e-1701-40d9-ef26-1003d24d83ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9950\n",
            "\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Non-Cyberbullying       0.99      1.00      1.00       107\n",
            "    Cyberbullying       1.00      0.99      0.99        93\n",
            "\n",
            "         accuracy                           0.99       200\n",
            "        macro avg       1.00      0.99      0.99       200\n",
            "     weighted avg       1.00      0.99      0.99       200\n",
            "\n",
            "Input: I hate you! --> Prediction: Cyberbullying\n",
            "Input: You are amazing! 😊 --> Prediction: Non-Cyberbullying\n",
            "Input: 🫶🏽 --> Prediction: Non-Cyberbullying\n",
            "Input: 😡 --> Prediction: Cyberbullying\n",
            "Input: You are a failure! --> Prediction: Cyberbullying\n",
            "Input: Keep up the great work! 👍 --> Prediction: Non-Cyberbullying\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ✅ Define emoji-based classification (Expanded for multi-character emojis)\n",
        "CYBERBULLYING_EMOJIS = {\"😡\", \"👊\", \"💀\", \"🤬\", \"😠\", \"👿\", \"🖕\", \"💢\", \"🔪\", \"🖕🏽\", \"🖕🏻\", \"🖕🏾\", \"🖕🏿\"}\n",
        "NON_CYBERBULLYING_EMOJIS = {\"😊\", \"❤️\", \"💝\", \"👍\", \"😁\", \"😇\", \"🎉\", \"😂\", \"💖\", \"🥰\", \"🫶🏽\", \"🧑🏽‍🎨\"}\n",
        "\n",
        "# ✅ Function to check if input contains **only emojis**\n",
        "def contains_only_emojis(text):\n",
        "    text = text.strip()\n",
        "    emoji_count = sum(1 for char in text if char in emoji.EMOJI_DATA)  # Count valid emoji characters\n",
        "    return emoji_count == len(text)  # Ensure input contains only emojis\n",
        "\n",
        "# ✅ Fully Fixed Emoji Classification Function (Handles 🖕🏽, 🧑🏽‍🎨 correctly)\n",
        "def classify_emoji(input_text):\n",
        "    input_text = input_text.strip()\n",
        "    if contains_only_emojis(input_text):  # If the input is only emojis\n",
        "        if input_text in NON_CYBERBULLYING_EMOJIS:\n",
        "            return \"Non-Cyberbullying\"\n",
        "        elif input_text in CYBERBULLYING_EMOJIS:\n",
        "            return \"Cyberbullying\"\n",
        "        return \"Non-Cyberbullying\"  # Default if unknown emoji is present\n",
        "    return None  # If it's mixed with text, process normally\n",
        "\n",
        "# ✅ Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "# ✅ Load dataset (Update path if needed)\n",
        "dataset_path = \"expanded_cyberbullying_dataset.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# ✅ Preprocess dataset\n",
        "df[\"processed_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "# ✅ Split dataset into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"processed_text\"], df[\"label\"], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Create a Naïve Bayes classifier pipeline\n",
        "model_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),  # Convert text to numerical features\n",
        "    (\"classifier\", MultinomialNB())  # Train Naïve Bayes model\n",
        "])\n",
        "\n",
        "# ✅ Train the model\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Evaluate model performance\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred, target_names=[\"Non-Cyberbullying\", \"Cyberbullying\"])\n",
        "\n",
        "# ✅ Print results\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n",
        "\n",
        "# ✅ Final cyberbullying detection function (Text + Emoji)\n",
        "def predict_cyberbullying(user_input):\n",
        "    emoji_prediction = classify_emoji(user_input)  # Check for emoji classification first\n",
        "    if emoji_prediction:\n",
        "        return emoji_prediction  # If emoji-based classification is valid, return it\n",
        "\n",
        "    # Otherwise, classify using the trained model\n",
        "    processed_input = preprocess_text(user_input)\n",
        "    prediction = model_pipeline.predict([processed_input])[0]\n",
        "    return \"Cyberbullying\" if prediction == 1 else \"Non-Cyberbullying\"\n",
        "\n",
        "# ✅ USER INPUT SECTION - Interactive Testing\n",
        "print(\"\\n🔹 Cyberbullying Detection System 🔹\")\n",
        "print(\"Enter text or emojis to check for cyberbullying.\")\n",
        "print(\"Type 'exit' to stop the program.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter text or emojis: \").strip()\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Exiting the system. Have a great day! 😊\")\n",
        "        break\n",
        "\n",
        "    prediction = predict_cyberbullying(user_input)\n",
        "    print(f\"🔹 Prediction: {prediction}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLSltq6jZ4AK",
        "outputId": "edf94ff4-56ab-477b-9e7c-fd47d9703b38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9950\n",
            "\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Non-Cyberbullying       0.99      1.00      1.00       107\n",
            "    Cyberbullying       1.00      0.99      0.99        93\n",
            "\n",
            "         accuracy                           0.99       200\n",
            "        macro avg       1.00      0.99      0.99       200\n",
            "     weighted avg       1.00      0.99      0.99       200\n",
            "\n",
            "\n",
            "🔹 Cyberbullying Detection System 🔹\n",
            "Enter text or emojis to check for cyberbullying.\n",
            "Type 'exit' to stop the program.\n",
            "\n",
            "Enter text or emojis: exit\n",
            "Exiting the system. Have a great day! 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import emoji\n",
        "import gradio as gr\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ✅ Define emoji-based classification (Expanded for multi-character emojis)\n",
        "CYBERBULLYING_EMOJIS = {\"😡\", \"👊\", \"💀\", \"🤬\", \"😠\", \"👿\", \"🖕\", \"💢\", \"🔪\", \"🖕🏽\", \"🖕🏻\", \"🖕🏾\", \"🖕🏿\"}\n",
        "NON_CYBERBULLYING_EMOJIS = {\"😊\", \"❤️\", \"💝\", \"👍\", \"😁\", \"😇\", \"🎉\", \"😂\", \"💖\", \"🥰\", \"🫶🏽\", \"🧑🏽‍🎨\"}\n",
        "\n",
        "# ✅ Function to check if input contains **only emojis**\n",
        "def contains_only_emojis(text):\n",
        "    text = text.strip()\n",
        "    emoji_count = sum(1 for char in text if char in emoji.EMOJI_DATA)  # Count valid emoji characters\n",
        "    return emoji_count == len(text)  # Ensure input contains only emojis\n",
        "\n",
        "# ✅ Fully Fixed Emoji Classification Function\n",
        "def classify_emoji(input_text):\n",
        "    input_text = input_text.strip()\n",
        "    if contains_only_emojis(input_text):  # If the input is only emojis\n",
        "        if input_text in NON_CYBERBULLYING_EMOJIS:\n",
        "            return \"Non-Cyberbullying\"\n",
        "        elif input_text in CYBERBULLYING_EMOJIS:\n",
        "            return \"Cyberbullying\"\n",
        "        return \"Non-Cyberbullying\"  # Default if unknown emoji is present\n",
        "    return None  # If it's mixed with text, process normally\n",
        "\n",
        "# ✅ Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "# ✅ Load dataset (Update path if needed)\n",
        "dataset_path = \"expanded_cyberbullying_dataset.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# ✅ Preprocess dataset\n",
        "df[\"processed_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "# ✅ Split dataset into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"processed_text\"], df[\"label\"], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Create a Naïve Bayes classifier pipeline\n",
        "model_pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),  # Convert text to numerical features\n",
        "    (\"classifier\", MultinomialNB())  # Train Naïve Bayes model\n",
        "])\n",
        "\n",
        "# ✅ Train the model\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# ✅ Evaluate model performance\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred, target_names=[\"Non-Cyberbullying\", \"Cyberbullying\"])\n",
        "\n",
        "# ✅ Print results\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n",
        "\n",
        "# ✅ Final cyberbullying detection function (Text + Emoji)\n",
        "def predict_cyberbullying(user_input):\n",
        "    emoji_prediction = classify_emoji(user_input)  # Check for emoji classification first\n",
        "    if emoji_prediction:\n",
        "        return emoji_prediction  # If emoji-based classification is valid, return it\n",
        "\n",
        "    # Otherwise, classify using the trained model\n",
        "    processed_input = preprocess_text(user_input)\n",
        "    prediction = model_pipeline.predict([processed_input])[0]\n",
        "    return \"Cyberbullying\" if prediction == 1 else \"Non-Cyberbullying\"\n",
        "\n",
        "# ✅ GRADIO INTERFACE\n",
        "def gradio_interface(input_text):\n",
        "    result = predict_cyberbullying(input_text)\n",
        "    return f\"Prediction: {result}\"\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Cyberbullying Detection System\",\n",
        "    description=\"Enter a phrase or emoji to check if it is cyberbullying.\"\n",
        ")\n",
        "\n",
        "# ✅ Launch Gradio App\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "GuZczWBHZ67b",
        "outputId": "1eb7e081-a511-4825-b8ed-beb434a840f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9950\n",
            "\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "Non-Cyberbullying       0.99      1.00      1.00       107\n",
            "    Cyberbullying       1.00      0.99      0.99        93\n",
            "\n",
            "         accuracy                           0.99       200\n",
            "        macro avg       1.00      0.99      0.99       200\n",
            "     weighted avg       1.00      0.99      0.99       200\n",
            "\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://aee1e047ffe11d5cb9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aee1e047ffe11d5cb9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}